{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Network of Lookup Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2\n",
    "\n",
    "A network of k = 2 layers.\n",
    "The first layer has 2 luts.\n",
    "The second layer has 1 lut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = [([0,0,0],0),([0,0,0],1),([0,0,0],1),([0,0,1],1),([1,0,0],0),([1,1,0],0),([1,1,0],1)]\n",
    "X_train = np.array([[0,0,0],[0,0,0],[0,0,0],[0,0,1],[1,0,0],[1,1,0],[1,1,0]])\n",
    "y_train = np.array([0,1,1,1,0,0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LUT:\n",
    "    def __init__(self, inputs, indexes_0, indexes_1, k , index = []):\n",
    "        # build lut\n",
    "        self.k = k\n",
    "        if (index == []):\n",
    "            self.index = np.sort(np.random.choice(len(inputs[0]),k,replace = False))\n",
    "        else:\n",
    "            self.index = index\n",
    "        self.subset = inputs[:,self.index]\n",
    "        self.inv = np.arange(k-1,-1,-1)\n",
    "        self.output = np.zeros((2**k), int)\n",
    "        self.count_0 = np.zeros((2**k), int)\n",
    "        self.count_1 = np.zeros((2**k), int)\n",
    "        self.count(indexes_0,indexes_1)\n",
    "        \n",
    "    def count(self, indexes_0, indexes_1):\n",
    "        zeros = Counter(np.sort(self.get_index_vec_to_dec(self.subset[indexes_0])))\n",
    "        ones =  Counter(np.sort(self.get_index_vec_to_dec(self.subset[indexes_1])))\n",
    "        for key in zeros.keys():\n",
    "            self.count_0[key] = zeros[key]\n",
    "        for key in ones.keys():\n",
    "            self.count_1[key] = ones[key]\n",
    "        # compute lut\n",
    "        self.output[self.count_0 > self.count_1] = 0\n",
    "        self.output[self.count_0 < self.count_1] = 1\n",
    "        # picked uniformly at random\n",
    "        self.output[self.count_0 == self.count_1] = np.random.choice([0,1], len(self.output[self.count_0 == self.count_1]))\n",
    "        \n",
    "    def get_index_vec_to_dec(self, X , axis = 1):\n",
    "        dec_index = np.sum(X * np.power(2*np.ones(k,int),self.inv),axis= axis)\n",
    "        return dec_index\n",
    "    \n",
    "    def get_index_dec_to_vec(self, dec):\n",
    "        return \"{0:b}\".format(dec).zfill(self.k)\n",
    "    \n",
    "    def look(self, X):\n",
    "        # X is a numpy array\n",
    "        X = np.array(X)\n",
    "        return self.output[self.get_index_vec_to_dec(X[self.index], 0)]\n",
    "    \n",
    "    def look_array(self, dataset):\n",
    "        subdataset = dataset[:,self.index]\n",
    "        return self.output[self.get_index_vec_to_dec(subdataset)]\n",
    "        \n",
    "    def score(self, labels, dataset):\n",
    "        self.predicted = self.look_array(dataset)\n",
    "        return accuracy_score(labels,predicted)\n",
    "    \n",
    "    def show(self):\n",
    "        print(\"Look up table\")\n",
    "        print(\"Index = {}\".format(self.index))\n",
    "        print(\"  p    |  y0 |  y1 |  f   |\")\n",
    "        for i in range(len(self.output)):\n",
    "            if (self.count_0[i] == self.count_1[i]):\n",
    "                f = \"{}*\".format(self.output[i])\n",
    "            else:\n",
    "                f = \"{} \".format(self.output[i])\n",
    "            print(\"  {}   |  {}  |  {}  |  {}  |\".format(self.get_index_dec_to_vec(i), self.count_0[i], self.count_1[i], f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look up table\n",
      "Index = [0, 1]\n",
      "  p    |  y0 |  y1 |  f   |\n",
      "  00   |  1  |  3  |  1   |\n",
      "  01   |  0  |  0  |  0*  |\n",
      "  10   |  1  |  0  |  0   |\n",
      "  11   |  1  |  1  |  0*  |\n",
      "predict [0,0,0] : 1\n",
      "accuracy : 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "#index = np.sort(np.random.choice(len(train_set[0][0]),k,replace = False))\n",
    "k = 2\n",
    "index = [0,1]\n",
    "lut = LUT(X_train,np.where(y_train == 0), np.where(y_train == 1), 2, index)\n",
    "lut.show()\n",
    "print(\"predict [0,0,0] : {}\".format(lut.look(np.array([0,0,0]))))\n",
    "print(\"accuracy : {}\".format(lut.score(y_train, X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==== first layer === \n",
      "\n",
      "Look up table\n",
      "Index = [0 2]\n",
      "  p    |  y0 |  y1 |  f   |\n",
      "  00   |  1  |  2  |  1   |\n",
      "  01   |  0  |  1  |  1   |\n",
      "  10   |  2  |  1  |  0   |\n",
      "  11   |  0  |  0  |  0*  |\n",
      "Look up table\n",
      "Index = [1 2]\n",
      "  p    |  y0 |  y1 |  f   |\n",
      "  00   |  2  |  2  |  1*  |\n",
      "  01   |  0  |  1  |  1   |\n",
      "  10   |  1  |  1  |  1*  |\n",
      "  11   |  0  |  0  |  1*  |\n",
      "\n",
      " ==== second layer === \n",
      "\n",
      "Look up table\n",
      "Index = [0 1]\n",
      "  p    |  y0 |  y1 |  f   |\n",
      "  00   |  0  |  0  |  1*  |\n",
      "  01   |  2  |  1  |  0   |\n",
      "  10   |  0  |  0  |  0*  |\n",
      "  11   |  1  |  3  |  1   |\n"
     ]
    }
   ],
   "source": [
    "n_luts = [2, 1] # number of luts per layer\n",
    "k = 2 # sampling input\n",
    "\n",
    "# make a Network of look up table\n",
    "layers = []\n",
    "\n",
    "indexes_0 = np.where(y_train == 0) \n",
    "indexes_1 = np.where(y_train == 1)\n",
    "outputs = np.zeros((len(X_train),n_luts[0]),int)\n",
    "\n",
    "# first layer\n",
    "print(\" ==== first layer === \\n\")\n",
    "layer = []\n",
    "for i in range(n_luts[0]):\n",
    "    # build lut\n",
    "    lut = LUT(X_train, indexes_0, indexes_1, k)\n",
    "    lut.show()\n",
    "    outputs[:,i] = lut.look_array(X_train)\n",
    "    layer.append(lut)\n",
    "layers.append(layer)\n",
    "\n",
    "# second layer\n",
    "print(\"\\n ==== second layer === \\n\")\n",
    "layer = []\n",
    "inputs = outputs\n",
    "outputs = np.zeros((len(X_train),n_luts[1]),int)\n",
    "for i in range(n_luts[1]):\n",
    "    lut = LUT(inputs, indexes_0, indexes_1, k)\n",
    "    lut.show()\n",
    "    outputs[:,i] = lut.look_array(inputs)\n",
    "    layer.append(lut)\n",
    "layers.append(layer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n",
    "\n",
    "A Network with 5 hidden layers of 1024 luts and 1 lut in the output layer. k = 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75bf2b7d5adb4e278a5267a1a841988e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FloatProgress</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FloatProgress(value=0.0, max=60000.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d28f750f6d4fe593d3450a51facef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FloatProgress</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FloatProgress(value=0.0, max=10000.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def loadMNIST(prefix, folder):\n",
    "    intType = np.dtype( 'int32' ).newbyteorder( '>' )\n",
    "    nMetaDataBytes = 4 * intType.itemsize\n",
    "\n",
    "    data = np.fromfile( folder + \"/\" + prefix + '-images.idx3-ubyte', dtype = 'ubyte' )\n",
    "    magicBytes, nImages, width, height = np.frombuffer( data[:nMetaDataBytes].tobytes(), intType )\n",
    "    data = data[nMetaDataBytes:].astype( dtype = 'float32' ).reshape( [ nImages, width, height ] )\n",
    "\n",
    "    labels = np.fromfile( folder + \"/\" + prefix + '-labels.idx1-ubyte',\n",
    "                          dtype = 'ubyte' )[2 * intType.itemsize:]\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "trainingImages, trainingLabels = loadMNIST( \"train\", \"./data/mnist\" )\n",
    "testImages, testLabels = loadMNIST( \"t10k\", \"./data/mnist\" )\n",
    "\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "\n",
    "X_train = np.zeros((60000,784), int)\n",
    "y_train = np.zeros((60000),int)\n",
    "threshold=0.3 * 255\n",
    "f = FloatProgress(min=0, max=trainingImages.shape[0])\n",
    "display(f)\n",
    "for i in range(trainingImages.shape[0]): \n",
    "    f.value+=1\n",
    "    X_train[i,:]= 1.0*(trainingImages[i].reshape(784)>threshold)\n",
    "y_train[trainingLabels>4] = 1\n",
    "print(X_train.shape)\n",
    "\n",
    "X_test = np.zeros((10000,784), int)\n",
    "y_test = np.zeros((10000),int)\n",
    "threshold=0.3 * 255\n",
    "f = FloatProgress(min=0, max=testImages.shape[0])\n",
    "display(f)\n",
    "for i in range(testImages.shape[0]): \n",
    "    f.value+=1\n",
    "    X_test[i,:]= 1.0*(testImages[i].reshape(784)>threshold)\n",
    "y_test[testLabels>4] = 1\n",
    "print(X_test.shape)\n",
    "\n",
    "with open('./data/mnist/mnist_X_train.p', 'wb') as f:\n",
    "    pickle.dump(X_train, f)\n",
    "with open('./data/mnist/mnist_y_train.p', 'wb') as f:\n",
    "    pickle.dump(y_train, f)\n",
    "with open('./data/mnist/mnist_X_test.p', 'wb') as f:\n",
    "    pickle.dump(X_test, f)\n",
    "with open('./data/mnist/mnist_y_test.p', 'wb') as f:\n",
    "    pickle.dump(y_test, f)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/mnist/mnist_X_train.p', 'rb') as f:\n",
    "    X_train = pickle.load(f)\n",
    "with open('./data/mnist/mnist_y_train.p', 'rb') as f:\n",
    "    y_train = pickle.load(f)\n",
    "with open('./data/mnist/mnist_X_test.p', 'rb') as f:\n",
    "    X_test = pickle.load(f)\n",
    "with open('./data/mnist/mnist_y_test.p', 'rb') as f:\n",
    "    y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29466d1d3c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29464cd1080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0].reshape(28,28) , matplotlib.pyplot.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0 nb luts : 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 784/784 [01:04<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 1 nb luts : 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1024/1024 [01:22<00:00, 12.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 2 nb luts : 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1024/1024 [01:22<00:00, 12.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 3 nb luts : 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1024/1024 [01:22<00:00, 12.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 4 nb luts : 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1024/1024 [01:23<00:00, 11.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 5 nb luts : 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1024/1024 [01:25<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 6 nb luts : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.84it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n_luts = [784, 1024,1024,1024,1024,1024,1] # number of luts per layer\n",
    "k = 8 # sampling input\n",
    "layers = []\n",
    "\n",
    "inputs = np.zeros((len(y_train),8),int)\n",
    "indexes_0 = np.where(y_train == 0) \n",
    "indexes_1 = np.where(y_train == 1)\n",
    "\n",
    "train_accuracy = []\n",
    "\n",
    "# input layer\n",
    "l = 0\n",
    "print(\"layer {} nb luts : {}\".format(l, n_luts[l]))\n",
    "layer = []\n",
    "accuracy = []\n",
    "inputs = X_train\n",
    "outputs = np.zeros((len(y_train),n_luts[l]),int)\n",
    "for i in tqdm(range(n_luts[0])):\n",
    "    # build lut\n",
    "    lut = LUT(inputs, indexes_0, indexes_1, k)\n",
    "    outputs[:,i] = lut.look_array(inputs)\n",
    "    layer.append(lut)\n",
    "    accuracy.append(accuracy_score(y_train, outputs[:,i]))\n",
    "layers.append(layer)\n",
    "train_accuracy.append(accuracy)\n",
    "\n",
    "# 5 hidden layers + 1 output layer\n",
    "for l in range(1,7):\n",
    "    print(\"layer {} nb luts : {}\".format(l, n_luts[l]))\n",
    "    layer = []\n",
    "    accuracy = []\n",
    "    inputs = outputs\n",
    "    outputs = np.zeros((len(y_train),n_luts[l]),int)\n",
    "    for i in tqdm(range(n_luts[l])):\n",
    "        lut = LUT(inputs, indexes_0, indexes_1, k)\n",
    "        outputs[:,i] = lut.look_array(inputs)\n",
    "        layer.append(lut)\n",
    "        accuracy.append(accuracy_score(y_train, outputs[:,i]))\n",
    "    layers.append(layer)\n",
    "    train_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1 : Training accuracy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>784.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.611867</td>\n",
       "      <td>0.755240</td>\n",
       "      <td>0.843522</td>\n",
       "      <td>0.879176</td>\n",
       "      <td>0.893693</td>\n",
       "      <td>0.901817</td>\n",
       "      <td>0.907967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.042915</td>\n",
       "      <td>0.018114</td>\n",
       "      <td>0.006528</td>\n",
       "      <td>0.002940</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.511400</td>\n",
       "      <td>0.688167</td>\n",
       "      <td>0.822600</td>\n",
       "      <td>0.870550</td>\n",
       "      <td>0.890050</td>\n",
       "      <td>0.900050</td>\n",
       "      <td>0.907967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.581438</td>\n",
       "      <td>0.743533</td>\n",
       "      <td>0.839142</td>\n",
       "      <td>0.877117</td>\n",
       "      <td>0.892917</td>\n",
       "      <td>0.901462</td>\n",
       "      <td>0.907967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.607625</td>\n",
       "      <td>0.755725</td>\n",
       "      <td>0.843658</td>\n",
       "      <td>0.879375</td>\n",
       "      <td>0.893675</td>\n",
       "      <td>0.901783</td>\n",
       "      <td>0.907967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.642892</td>\n",
       "      <td>0.767517</td>\n",
       "      <td>0.848058</td>\n",
       "      <td>0.881154</td>\n",
       "      <td>0.894450</td>\n",
       "      <td>0.902167</td>\n",
       "      <td>0.907967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.739517</td>\n",
       "      <td>0.802800</td>\n",
       "      <td>0.862533</td>\n",
       "      <td>0.889133</td>\n",
       "      <td>0.897600</td>\n",
       "      <td>0.903900</td>\n",
       "      <td>0.907967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4  \\\n",
       "count  784.000000  1024.000000  1024.000000  1024.000000  1024.000000   \n",
       "mean     0.611867     0.755240     0.843522     0.879176     0.893693   \n",
       "std      0.042915     0.018114     0.006528     0.002940     0.001192   \n",
       "min      0.511400     0.688167     0.822600     0.870550     0.890050   \n",
       "25%      0.581438     0.743533     0.839142     0.877117     0.892917   \n",
       "50%      0.607625     0.755725     0.843658     0.879375     0.893675   \n",
       "75%      0.642892     0.767517     0.848058     0.881154     0.894450   \n",
       "max      0.739517     0.802800     0.862533     0.889133     0.897600   \n",
       "\n",
       "                 5         6  \n",
       "count  1024.000000  1.000000  \n",
       "mean      0.901817  0.907967  \n",
       "std       0.000582       NaN  \n",
       "min       0.900050  0.907967  \n",
       "25%       0.901462  0.907967  \n",
       "50%       0.901783  0.907967  \n",
       "75%       0.902167  0.907967  \n",
       "max       0.903900  0.907967  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Experiment 1 : Training accuracy\\n\")\n",
    "df = pd.DataFrame(train_accuracy).transpose()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 784/784 [00:05<00:00, 151.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1024/1024 [00:07<00:00, 139.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1024/1024 [00:07<00:00, 132.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1024/1024 [00:07<00:00, 137.61it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1024/1024 [00:07<00:00, 142.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1024/1024 [00:07<00:00, 146.00it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 125.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# Compute test accuracy\n",
    "\n",
    "# input layer\n",
    "k = 8\n",
    "\n",
    "test_accuracy = []\n",
    "\n",
    "inputs = X_test\n",
    "outputs = np.zeros((len(X_test),len(layers[0])),int)\n",
    "accuracy = []\n",
    "for i in tqdm(range(len(layers[0]))):\n",
    "    score = layers[0][i].score(y_test, inputs)\n",
    "    outputs[:,i] = layers[0][i].look_array(inputs)\n",
    "    accuracy.append(score)\n",
    "test_accuracy.append(accuracy)\n",
    "    \n",
    "for layer in layers[1:]:\n",
    "    accuracy = []\n",
    "    inputs = outputs\n",
    "    outputs = np.zeros((len(X_test),len(layer)),int)\n",
    "    for i in tqdm(range(len(layer))):\n",
    "        score = layer[i].score(y_test, inputs)\n",
    "        outputs[:,i] = layer[i].look_array(inputs)\n",
    "        #outputs[:,i] = lut.predicted\n",
    "        accuracy.append(score)\n",
    "    test_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1 : Test accuracy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>784.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.614273</td>\n",
       "      <td>0.757236</td>\n",
       "      <td>0.841769</td>\n",
       "      <td>0.872953</td>\n",
       "      <td>0.881972</td>\n",
       "      <td>0.884727</td>\n",
       "      <td>0.8851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.046526</td>\n",
       "      <td>0.019889</td>\n",
       "      <td>0.007540</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.508900</td>\n",
       "      <td>0.688600</td>\n",
       "      <td>0.814900</td>\n",
       "      <td>0.860200</td>\n",
       "      <td>0.875800</td>\n",
       "      <td>0.880400</td>\n",
       "      <td>0.8851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.579750</td>\n",
       "      <td>0.744200</td>\n",
       "      <td>0.836800</td>\n",
       "      <td>0.870700</td>\n",
       "      <td>0.880600</td>\n",
       "      <td>0.883700</td>\n",
       "      <td>0.8851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.609400</td>\n",
       "      <td>0.758200</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.873000</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.884700</td>\n",
       "      <td>0.8851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.647300</td>\n",
       "      <td>0.771425</td>\n",
       "      <td>0.846700</td>\n",
       "      <td>0.875400</td>\n",
       "      <td>0.883325</td>\n",
       "      <td>0.885800</td>\n",
       "      <td>0.8851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.749000</td>\n",
       "      <td>0.806800</td>\n",
       "      <td>0.866200</td>\n",
       "      <td>0.888200</td>\n",
       "      <td>0.889400</td>\n",
       "      <td>0.890500</td>\n",
       "      <td>0.8851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4  \\\n",
       "count  784.000000  1024.000000  1024.000000  1024.000000  1024.000000   \n",
       "mean     0.614273     0.757236     0.841769     0.872953     0.881972   \n",
       "std      0.046526     0.019889     0.007540     0.003648     0.002017   \n",
       "min      0.508900     0.688600     0.814900     0.860200     0.875800   \n",
       "25%      0.579750     0.744200     0.836800     0.870700     0.880600   \n",
       "50%      0.609400     0.758200     0.842000     0.873000     0.882000   \n",
       "75%      0.647300     0.771425     0.846700     0.875400     0.883325   \n",
       "max      0.749000     0.806800     0.866200     0.888200     0.889400   \n",
       "\n",
       "                 5       6  \n",
       "count  1024.000000  1.0000  \n",
       "mean      0.884727  0.8851  \n",
       "std       0.001489     NaN  \n",
       "min       0.880400  0.8851  \n",
       "25%       0.883700  0.8851  \n",
       "50%       0.884700  0.8851  \n",
       "75%       0.885800  0.8851  \n",
       "max       0.890500  0.8851  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Experiment 1 : Test accuracy\\n\")\n",
    "df = pd.DataFrame(test_accuracy).transpose()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
