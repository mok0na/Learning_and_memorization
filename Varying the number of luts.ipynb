{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LUT:\n",
    "    def __init__(self, inputs, indexes_0, indexes_1, k , index = []):\n",
    "        # build lut\n",
    "        self.k = k\n",
    "        if (index == []):\n",
    "            self.index = np.sort(np.random.choice(len(inputs[0]),k,replace = False))\n",
    "        else:\n",
    "            self.index = index\n",
    "        self.inv = np.arange(k-1,-1,-1)\n",
    "        self.output = np.zeros((2**k), int)\n",
    "        self.count_0 = np.zeros((2**k), int)\n",
    "        self.count_1 = np.zeros((2**k), int)\n",
    "        self.count(inputs[:,self.index], indexes_0,indexes_1)\n",
    "        \n",
    "    def count(self, subset, indexes_0, indexes_1):\n",
    "        zeros = Counter(np.sort(self.get_index_vec_to_dec(subset[indexes_0])))\n",
    "        ones =  Counter(np.sort(self.get_index_vec_to_dec(subset[indexes_1])))\n",
    "        for key in zeros.keys():\n",
    "            self.count_0[key] = zeros[key]\n",
    "        for key in ones.keys():\n",
    "            self.count_1[key] = ones[key]\n",
    "        # compute lut\n",
    "        self.output[self.count_0 > self.count_1] = 0\n",
    "        self.output[self.count_0 < self.count_1] = 1\n",
    "        # picked uniformly at random\n",
    "        self.output[self.count_0 == self.count_1] = np.random.choice([0,1], len(self.output[self.count_0 == self.count_1]))\n",
    "        \n",
    "    def get_index_vec_to_dec(self, X , axis = 1):\n",
    "        dec_index = np.sum(X * np.power(2*np.ones(self.k,int),self.inv),axis= axis)\n",
    "        return dec_index\n",
    "    \n",
    "    def get_index_dec_to_vec(self, dec):\n",
    "        return \"{0:b}\".format(dec).zfill(self.k)\n",
    "    \n",
    "    def look(self, X):\n",
    "        # X is a numpy array\n",
    "        X = np.array(X)\n",
    "        return self.output[self.get_index_vec_to_dec(X[self.index], 0)]\n",
    "    \n",
    "    def look_array(self, dataset):\n",
    "        subdataset = dataset[:,self.index]\n",
    "        return self.output[self.get_index_vec_to_dec(subdataset)]\n",
    "        \n",
    "    def score(self, labels, dataset):\n",
    "        predicted = self.look_array(dataset)\n",
    "        return accuracy_score(labels,predicted)\n",
    "    \n",
    "    def show(self):\n",
    "        print(\"Look up table\")\n",
    "        print(\"Index = {}\".format(self.index))\n",
    "        print(\"  p    |  y0 |  y1 |  f   |\")\n",
    "        for i in range(len(self.output)):\n",
    "            if (self.count_0[i] == self.count_1[i]):\n",
    "                f = \"{}*\".format(self.output[i])\n",
    "            else:\n",
    "                f = \"{} \".format(self.output[i])\n",
    "            print(\"  {}   |  {}  |  {}  |  {}  |\".format(self.get_index_dec_to_vec(i), self.count_0[i], self.count_1[i], f))\n",
    "            \n",
    "    def clean(self):\n",
    "        self.count_0 = None\n",
    "        self.count_1 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLUTS :\n",
    "    def __init__(self,k,n_luts = [1024,512,512,256,16,1], n_layer = 6):\n",
    "        self.layers = []\n",
    "        self.k = k\n",
    "        self.n_layer = n_layer\n",
    "        self.n_luts = n_luts\n",
    "    \n",
    "    def train(self,X_train,y_train, indexes_0, indexes_1):\n",
    "\n",
    "        inputs = X_train\n",
    "        outputs = inputs\n",
    "        # hidden layers + 1 output layer\n",
    "        for l in range(self.n_layer):\n",
    "            layer = []\n",
    "            inputs = outputs\n",
    "            outputs = np.zeros((len(X_train),self.n_luts[l]),int)\n",
    "            for i in range(n_luts[l]):\n",
    "                lut = LUT(inputs, indexes_0, indexes_1, self.k)\n",
    "                outputs[:,i] = lut.look_array(inputs)\n",
    "                layer.append(lut)\n",
    "            self.layers.append(layer)\n",
    "        return outputs\n",
    "    \n",
    "    def predict(self,X,y):\n",
    "        inputs = X\n",
    "        outputs = inputs\n",
    "        for layer in self.layers:\n",
    "            inputs = outputs\n",
    "            outputs = np.zeros((len(X),len(layer)),int)\n",
    "            for i in range(len(layer)):\n",
    "                outputs[:,i] = layer[i].look_array(inputs)\n",
    "        return outputs\n",
    "    \n",
    "    def score(self,X,y):\n",
    "        return accuracy_score(y, self.predict(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/mnist/mnist_X_train.p', 'rb') as f:\n",
    "    X_train = pickle.load(f)\n",
    "with open('./data/mnist/binarized_mnist_y_train.p', 'rb') as f:\n",
    "    y_train = pickle.load(f)\n",
    "with open('./data/mnist/mnist_X_test.p', 'rb') as f:\n",
    "    X_test = pickle.load(f)\n",
    "with open('./data/mnist/binarized_mnist_y_test.p', 'rb') as f:\n",
    "    y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test varying the number of luts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0 nb luts : 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 784/784 [00:12<00:00, 61.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 1 nb luts : 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:05<00:00, 13.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 2 nb luts : 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:05<00:00, 10.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 3 nb luts : 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:05<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 4 nb luts : 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:04<00:00, 13.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 5 nb luts : 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 12.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 6 nb luts : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent : 34.74s\n",
      "Experiment 1 bis : Training accuracy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>784.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.507220</td>\n",
       "      <td>0.615896</td>\n",
       "      <td>0.752570</td>\n",
       "      <td>0.823302</td>\n",
       "      <td>0.849653</td>\n",
       "      <td>0.862085</td>\n",
       "      <td>0.86985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.036831</td>\n",
       "      <td>0.044488</td>\n",
       "      <td>0.021528</td>\n",
       "      <td>0.006580</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.402167</td>\n",
       "      <td>0.517467</td>\n",
       "      <td>0.695167</td>\n",
       "      <td>0.805350</td>\n",
       "      <td>0.842200</td>\n",
       "      <td>0.860633</td>\n",
       "      <td>0.86985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.495071</td>\n",
       "      <td>0.582087</td>\n",
       "      <td>0.736204</td>\n",
       "      <td>0.819758</td>\n",
       "      <td>0.848258</td>\n",
       "      <td>0.861617</td>\n",
       "      <td>0.86985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.509933</td>\n",
       "      <td>0.607817</td>\n",
       "      <td>0.755658</td>\n",
       "      <td>0.823675</td>\n",
       "      <td>0.849992</td>\n",
       "      <td>0.861950</td>\n",
       "      <td>0.86985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.513792</td>\n",
       "      <td>0.640533</td>\n",
       "      <td>0.769258</td>\n",
       "      <td>0.827817</td>\n",
       "      <td>0.851162</td>\n",
       "      <td>0.862625</td>\n",
       "      <td>0.86985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.668500</td>\n",
       "      <td>0.714183</td>\n",
       "      <td>0.787350</td>\n",
       "      <td>0.836833</td>\n",
       "      <td>0.854683</td>\n",
       "      <td>0.863417</td>\n",
       "      <td>0.86985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0          1          2          3          4         5  \\\n",
       "count  784.000000  64.000000  64.000000  64.000000  64.000000  8.000000   \n",
       "mean     0.507220   0.615896   0.752570   0.823302   0.849653  0.862085   \n",
       "std      0.036831   0.044488   0.021528   0.006580   0.002479  0.000937   \n",
       "min      0.402167   0.517467   0.695167   0.805350   0.842200  0.860633   \n",
       "25%      0.495071   0.582087   0.736204   0.819758   0.848258  0.861617   \n",
       "50%      0.509933   0.607817   0.755658   0.823675   0.849992  0.861950   \n",
       "75%      0.513792   0.640533   0.769258   0.827817   0.851162  0.862625   \n",
       "max      0.668500   0.714183   0.787350   0.836833   0.854683  0.863417   \n",
       "\n",
       "             6  \n",
       "count  1.00000  \n",
       "mean   0.86985  \n",
       "std        NaN  \n",
       "min    0.86985  \n",
       "25%    0.86985  \n",
       "50%    0.86985  \n",
       "75%    0.86985  \n",
       "max    0.86985  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_luts = [784,64,64,64,64,8,1] # number of luts per layer\n",
    "k = 8 # sampling input\n",
    "layers = []\n",
    "\n",
    "inputs = np.zeros((len(y_train),8),int)\n",
    "indexes_0 = np.where(y_train == 0) \n",
    "indexes_1 = np.where(y_train == 1)\n",
    "\n",
    "train_accuracy = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# input layer\n",
    "l = 0\n",
    "print(\"layer {} nb luts : {}\".format(l, n_luts[l]))\n",
    "layer = []\n",
    "accuracy = []\n",
    "inputs = X_train\n",
    "outputs = np.zeros((len(y_train),n_luts[l]),int)\n",
    "for i in tqdm(range(n_luts[0])):\n",
    "    # build lut\n",
    "    #lut = LUT(inputs, indexes_0, indexes_1, 1, index = [i])\n",
    "    outputs[:,i] = inputs[:,i]\n",
    "    #layer.append(lut)\n",
    "    accuracy.append(accuracy_score(y_train, outputs[:,i]))\n",
    "layers.append(layer)\n",
    "train_accuracy.append(accuracy)\n",
    "\n",
    "# 5 hidden layers + 1 output layer\n",
    "for l in range(1,len(n_luts)):\n",
    "    print(\"layer {} nb luts : {}\".format(l, n_luts[l]))\n",
    "    layer = []\n",
    "    accuracy = []\n",
    "    inputs = outputs\n",
    "    outputs = np.zeros((len(y_train),n_luts[l]),int)\n",
    "    for i in tqdm(range(n_luts[l])):\n",
    "        lut = LUT(inputs, indexes_0, indexes_1, k)\n",
    "        outputs[:,i] = lut.look_array(inputs)\n",
    "        layer.append(lut)\n",
    "        accuracy.append(accuracy_score(y_train, outputs[:,i]))\n",
    "    layers.append(layer)\n",
    "    train_accuracy.append(accuracy)\n",
    "    \n",
    "end = time.time() - start\n",
    "print(\"Time spent : {:.2f}s\".format(end))\n",
    "\n",
    "print(\"Experiment 1 bis : Training accuracy\\n\")\n",
    "df = pd.DataFrame(train_accuracy).transpose()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 784/784 [00:02<00:00, 359.93it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 64/64 [00:00<00:00, 144.19it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 64/64 [00:00<00:00, 185.45it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 64/64 [00:00<00:00, 175.81it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 64/64 [00:00<00:00, 164.13it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 195.48it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 200.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent : 3.86s\n",
      "Experiment 1bis : Test accuracy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>784.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.511235</td>\n",
       "      <td>0.621620</td>\n",
       "      <td>0.758478</td>\n",
       "      <td>0.825833</td>\n",
       "      <td>0.847450</td>\n",
       "      <td>0.854600</td>\n",
       "      <td>0.8549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.038818</td>\n",
       "      <td>0.049406</td>\n",
       "      <td>0.024504</td>\n",
       "      <td>0.007608</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.391300</td>\n",
       "      <td>0.519100</td>\n",
       "      <td>0.690900</td>\n",
       "      <td>0.801700</td>\n",
       "      <td>0.838000</td>\n",
       "      <td>0.851400</td>\n",
       "      <td>0.8549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.497475</td>\n",
       "      <td>0.586900</td>\n",
       "      <td>0.740325</td>\n",
       "      <td>0.822025</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>0.853650</td>\n",
       "      <td>0.8549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.513900</td>\n",
       "      <td>0.614500</td>\n",
       "      <td>0.759900</td>\n",
       "      <td>0.826100</td>\n",
       "      <td>0.847800</td>\n",
       "      <td>0.855050</td>\n",
       "      <td>0.8549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.517125</td>\n",
       "      <td>0.658200</td>\n",
       "      <td>0.777125</td>\n",
       "      <td>0.831800</td>\n",
       "      <td>0.849500</td>\n",
       "      <td>0.856050</td>\n",
       "      <td>0.8549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.684600</td>\n",
       "      <td>0.725900</td>\n",
       "      <td>0.799300</td>\n",
       "      <td>0.839500</td>\n",
       "      <td>0.857300</td>\n",
       "      <td>0.856300</td>\n",
       "      <td>0.8549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0          1          2          3          4         5  \\\n",
       "count  784.000000  64.000000  64.000000  64.000000  64.000000  8.000000   \n",
       "mean     0.511235   0.621620   0.758478   0.825833   0.847450  0.854600   \n",
       "std      0.038818   0.049406   0.024504   0.007608   0.003467  0.001752   \n",
       "min      0.391300   0.519100   0.690900   0.801700   0.838000  0.851400   \n",
       "25%      0.497475   0.586900   0.740325   0.822025   0.845000  0.853650   \n",
       "50%      0.513900   0.614500   0.759900   0.826100   0.847800  0.855050   \n",
       "75%      0.517125   0.658200   0.777125   0.831800   0.849500  0.856050   \n",
       "max      0.684600   0.725900   0.799300   0.839500   0.857300  0.856300   \n",
       "\n",
       "            6  \n",
       "count  1.0000  \n",
       "mean   0.8549  \n",
       "std       NaN  \n",
       "min    0.8549  \n",
       "25%    0.8549  \n",
       "50%    0.8549  \n",
       "75%    0.8549  \n",
       "max    0.8549  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute test accuracy\n",
    "\n",
    "# input layer\n",
    "k = 8\n",
    "\n",
    "test_accuracy = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "inputs = X_test\n",
    "outputs = np.zeros((len(X_test),n_luts[0]),int)\n",
    "accuracy = []\n",
    "for i in tqdm(range(n_luts[0])):\n",
    "    outputs[:,i] = inputs[:,i]\n",
    "    accuracy.append(accuracy_score(y_test, outputs[:,i]))\n",
    "test_accuracy.append(accuracy)\n",
    "    \n",
    "for layer in layers[1:]:\n",
    "    accuracy = []\n",
    "    inputs = outputs\n",
    "    outputs = np.zeros((len(X_test),len(layer)),int)\n",
    "    for i in tqdm(range(len(layer))):\n",
    "        score = layer[i].score(y_test, inputs)\n",
    "        outputs[:,i] = layer[i].look_array(inputs)\n",
    "        accuracy.append(score)\n",
    "    test_accuracy.append(accuracy)\n",
    "\n",
    "end = time.time() - start\n",
    "print(\"Time spent : {:.2f}s\".format(end))\n",
    "\n",
    "print(\"Experiment 1bis : Test accuracy\\n\")\n",
    "df = pd.DataFrame(test_accuracy).transpose()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x18d81204ef0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_luts = [784,64,64,64,64,8,1] # number of luts per layer\n",
    "k = 8 # sampling input\n",
    "layers = []\n",
    "\n",
    "inputs = np.zeros((len(y_train),8),int)\n",
    "indexes_0 = np.where(y_train == 0) \n",
    "indexes_1 = np.where(y_train == 1)\n",
    "\n",
    "train_accuracy = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# input layer\n",
    "l = 0\n",
    "print(\"layer {} nb luts : {}\".format(l, n_luts[l]))\n",
    "layer = []\n",
    "accuracy = []\n",
    "inputs = X_train\n",
    "outputs = np.zeros((len(y_train),n_luts[l]),int)\n",
    "for i in tqdm(range(n_luts[0])):\n",
    "    # build lut\n",
    "    #lut = LUT(inputs, indexes_0, indexes_1, 1, index = [i])\n",
    "    outputs[:,i] = inputs[:,i]\n",
    "    #layer.append(lut)\n",
    "    accuracy.append(accuracy_score(y_train, outputs[:,i]))\n",
    "layers.append(layer)\n",
    "train_accuracy.append(accuracy)\n",
    "\n",
    "# 5 hidden layers + 1 output layer\n",
    "for l in range(1,len(n_luts)):\n",
    "    print(\"layer {} nb luts : {}\".format(l, n_luts[l]))\n",
    "    layer = []\n",
    "    accuracy = []\n",
    "    inputs = outputs\n",
    "    outputs = np.zeros((len(y_train),n_luts[l]),int)\n",
    "    for i in tqdm(range(n_luts[l])):\n",
    "        lut = LUT(inputs, indexes_0, indexes_1, k)\n",
    "        outputs[:,i] = lut.look_array(inputs)\n",
    "        layer.append(lut)\n",
    "        accuracy.append(accuracy_score(y_train, outputs[:,i]))\n",
    "    layers.append(layer)\n",
    "    train_accuracy.append(accuracy)\n",
    "    \n",
    "end = time.time() - start\n",
    "print(\"Time spent : {:.2f}s\".format(end))\n",
    "\n",
    "print(\"Experiment 1 bis : Training accuracy\\n\")\n",
    "df = pd.DataFrame(train_accuracy).transpose()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute test accuracy\n",
    "\n",
    "# input layer\n",
    "k = 8\n",
    "\n",
    "test_accuracy = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "inputs = X_test\n",
    "outputs = np.zeros((len(X_test),n_luts[0]),int)\n",
    "accuracy = []\n",
    "for i in tqdm(range(n_luts[0])):\n",
    "    outputs[:,i] = inputs[:,i]\n",
    "    accuracy.append(accuracy_score(y_test, outputs[:,i]))\n",
    "test_accuracy.append(accuracy)\n",
    "    \n",
    "for layer in layers[1:]:\n",
    "    accuracy = []\n",
    "    inputs = outputs\n",
    "    outputs = np.zeros((len(X_test),len(layer)),int)\n",
    "    for i in tqdm(range(len(layer))):\n",
    "        score = layer[i].score(y_test, inputs)\n",
    "        outputs[:,i] = layer[i].look_array(inputs)\n",
    "        accuracy.append(score)\n",
    "    test_accuracy.append(accuracy)\n",
    "\n",
    "end = time.time() - start\n",
    "print(\"Time spent : {:.2f}s\".format(end))\n",
    "\n",
    "print(\"Experiment 1bis : Test accuracy\\n\")\n",
    "df = pd.DataFrame(test_accuracy).transpose()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2 training accuracy : 0.702\n",
      "k = 2 test accuracy : 0.715\n",
      "Time spent :193.80s\n",
      "k = 4 training accuracy : 0.816\n",
      "k = 4 test accuracy : 0.819\n",
      "Time spent :217.41s\n",
      "k = 6 training accuracy : 0.856\n",
      "k = 6 test accuracy : 0.854\n",
      "Time spent :255.88s\n",
      "k = 8 training accuracy : 0.904\n",
      "k = 8 test accuracy : 0.882\n",
      "Time spent :295.56s\n",
      "k = 10 training accuracy : 0.957\n",
      "k = 10 test accuracy : 0.902\n",
      "Time spent :338.51s\n",
      "k = 12 training accuracy : 0.990\n",
      "k = 12 test accuracy : 0.902\n",
      "Time spent :387.90s\n",
      "k = 14 training accuracy : 0.999\n",
      "k = 14 test accuracy : 0.822\n",
      "Time spent :437.24s\n",
      "k = 16 training accuracy : 1.000\n",
      "k = 16 test accuracy : 0.659\n",
      "Time spent :505.93s\n",
      "Total Time spent : 2633.20s\n"
     ]
    }
   ],
   "source": [
    "n_luts = [1024,512,512,256,16,1] # number of luts per layer\n",
    "k_list = [2,4,6,8,10,12,14,16] # sampling input\n",
    "\n",
    "nn_list = []\n",
    "\n",
    "indexes_0 = np.where(y_train == 0) \n",
    "indexes_1 = np.where(y_train == 1)\n",
    "\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for k in k_list:\n",
    "    interm = time.time()\n",
    "    \n",
    "    nn = NLUTS(k,n_luts)\n",
    "    outputs = nn.train(X_train,y_train, indexes_0, indexes_1)\n",
    "    nn_list.append(nn)\n",
    "    print(\"k = {} training accuracy : {:.3f}\".format(k,accuracy_score(y_train, outputs)))\n",
    "    train_accuracy.append(accuracy_score(y_train, outputs))\n",
    "    print(\"k = {} test accuracy : {:.3f}\".format(k,nn.score(X_test,y_test)))\n",
    "    test_accuracy.append(nn.score(X_test,y_test))\n",
    "    \n",
    "    end = time.time() - interm\n",
    "    print(\"Time spent :{:.2f}s\".format(end))\n",
    "end = time.time() - start\n",
    "print(\"Total Time spent : {:.2f}s\".format(end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2 training accuracy : 0.706\n",
      "k = 2 test accuracy : 0.719\n",
      "Time spent :100.00s\n",
      "k = 4 training accuracy : 0.818\n",
      "k = 4 test accuracy : 0.827\n",
      "Time spent :115.21s\n",
      "k = 6 training accuracy : 0.866\n",
      "k = 6 test accuracy : 0.862\n",
      "Time spent :138.67s\n",
      "k = 8 training accuracy : 0.905\n",
      "k = 8 test accuracy : 0.884\n",
      "Time spent :154.91s\n",
      "k = 10 training accuracy : 0.953\n",
      "k = 10 test accuracy : 0.899\n",
      "Time spent :183.67s\n",
      "k = 12 training accuracy : 0.991\n",
      "k = 12 test accuracy : 0.905\n",
      "Time spent :207.19s\n",
      "k = 14 training accuracy : 0.999\n",
      "k = 14 test accuracy : 0.822\n",
      "Time spent :229.79s\n",
      "k = 16 training accuracy : 1.000\n",
      "k = 16 test accuracy : 0.678\n",
      "Time spent :262.78s\n",
      "Total Time spent : 1392.30s\n"
     ]
    }
   ],
   "source": [
    "n_luts = [512,256,256,64,16,1] # number of luts per layer\n",
    "k_list = [2,4,6,8,10,12,14,16] # sampling input\n",
    "\n",
    "nn_list = []\n",
    "\n",
    "indexes_0 = np.where(y_train == 0) \n",
    "indexes_1 = np.where(y_train == 1)\n",
    "\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for k in k_list:\n",
    "    interm = time.time()\n",
    "    \n",
    "    nn = NLUTS(k,n_luts)\n",
    "    outputs = nn.train(X_train,y_train, indexes_0, indexes_1)\n",
    "    nn_list.append(nn)\n",
    "    print(\"k = {} training accuracy : {:.3f}\".format(k,accuracy_score(y_train, outputs)))\n",
    "    train_accuracy.append(accuracy_score(y_train, outputs))\n",
    "    print(\"k = {} test accuracy : {:.3f}\".format(k,nn.score(X_test,y_test)))\n",
    "    test_accuracy.append(nn.score(X_test,y_test))\n",
    "    \n",
    "    end = time.time() - interm\n",
    "    print(\"Time spent :{:.2f}s\".format(end))\n",
    "end = time.time() - start\n",
    "print(\"Total Time spent : {:.2f}s\".format(end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2 training accuracy : 0.656\n",
      "k = 2 test accuracy : 0.653\n",
      "Time spent :25.99s\n",
      "k = 4 training accuracy : 0.789\n",
      "k = 4 test accuracy : 0.795\n",
      "Time spent :31.18s\n",
      "k = 6 training accuracy : 0.844\n",
      "k = 6 test accuracy : 0.842\n",
      "Time spent :41.48s\n",
      "k = 8 training accuracy : 0.890\n",
      "k = 8 test accuracy : 0.876\n",
      "Time spent :43.06s\n",
      "k = 10 training accuracy : 0.935\n",
      "k = 10 test accuracy : 0.887\n",
      "Time spent :53.76s\n",
      "k = 12 training accuracy : 0.978\n",
      "k = 12 test accuracy : 0.893\n",
      "Time spent :64.56s\n",
      "k = 14 training accuracy : 0.997\n",
      "k = 14 test accuracy : 0.876\n",
      "Time spent :74.37s\n",
      "k = 16 training accuracy : 1.000\n",
      "k = 16 test accuracy : 0.782\n",
      "Time spent :86.89s\n",
      "Total Time spent : 421.32s\n"
     ]
    }
   ],
   "source": [
    "n_luts = [512,64,16,16,16,1] # number of luts per layer\n",
    "k_list = [2,4,6,8,10,12,14,16] # sampling input\n",
    "\n",
    "nn_list = []\n",
    "\n",
    "indexes_0 = np.where(y_train == 0) \n",
    "indexes_1 = np.where(y_train == 1)\n",
    "\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for k in k_list:\n",
    "    interm = time.time()\n",
    "    \n",
    "    nn = NLUTS(k,n_luts)\n",
    "    outputs = nn.train(X_train,y_train, indexes_0, indexes_1)\n",
    "    nn_list.append(nn)\n",
    "    print(\"k = {} training accuracy : {:.3f}\".format(k,accuracy_score(y_train, outputs)))\n",
    "    train_accuracy.append(accuracy_score(y_train, outputs))\n",
    "    print(\"k = {} test accuracy : {:.3f}\".format(k,nn.score(X_test,y_test)))\n",
    "    test_accuracy.append(nn.score(X_test,y_test))\n",
    "    \n",
    "    end = time.time() - interm\n",
    "    print(\"Time spent :{:.2f}s\".format(end))\n",
    "end = time.time() - start\n",
    "print(\"Total Time spent : {:.2f}s\".format(end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 12 training accuracy : 0.855\n",
      "k = 12 test accuracy : 0.836\n",
      "Time spent :4.75s\n",
      "k = 12 training accuracy : 0.912\n",
      "k = 12 test accuracy : 0.857\n",
      "Time spent :8.59s\n",
      "k = 12 training accuracy : 0.959\n",
      "k = 12 test accuracy : 0.861\n",
      "Time spent :15.38s\n",
      "k = 12 training accuracy : 0.960\n",
      "k = 12 test accuracy : 0.859\n",
      "Time spent :28.78s\n",
      "k = 12 training accuracy : 0.961\n",
      "k = 12 test accuracy : 0.856\n",
      "Time spent :62.48s\n",
      "k = 12 training accuracy : 0.964\n",
      "k = 12 test accuracy : 0.865\n",
      "Time spent :125.70s\n",
      "Total Time spent : 245.70s\n"
     ]
    }
   ],
   "source": [
    "n_luts_list =[[32]*2**i+[1] for i in range(6)]  # number of luts per layer\n",
    "n_layers = [2**i+1 for i in range(6)]\n",
    "k = 12 # sampling input\n",
    "\n",
    "nn_list = []\n",
    "\n",
    "indexes_0 = np.where(y_train == 0) \n",
    "indexes_1 = np.where(y_train == 1)\n",
    "\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for n in range(len(n_luts_list)):\n",
    "    interm = time.time()\n",
    "    n_luts = n_luts_list[n]\n",
    "    nn = NLUTS(k,n_luts, n_layers[n])\n",
    "    outputs = nn.train(X_train,y_train, indexes_0, indexes_1)\n",
    "    nn_list.append(nn)\n",
    "    print(\"k = {} training accuracy : {:.3f}\".format(k,accuracy_score(y_train, outputs)))\n",
    "    train_accuracy.append(accuracy_score(y_train, outputs))\n",
    "    print(\"k = {} test accuracy : {:.3f}\".format(k,nn.score(X_test,y_test)))\n",
    "    test_accuracy.append(nn.score(X_test,y_test))\n",
    "    \n",
    "    end = time.time() - interm\n",
    "    print(\"Time spent :{:.2f}s\".format(end))\n",
    "end = time.time() - start\n",
    "print(\"Total Time spent : {:.2f}s\".format(end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 12 training accuracy : 0.851\n",
      "k = 12 test accuracy : 0.816\n",
      "Time spent :8.59s\n",
      "k = 12 training accuracy : 0.925\n",
      "k = 12 test accuracy : 0.873\n",
      "Time spent :16.66s\n",
      "k = 12 training accuracy : 0.969\n",
      "k = 12 test accuracy : 0.881\n",
      "Time spent :35.32s\n",
      "k = 12 training accuracy : 0.978\n",
      "k = 12 test accuracy : 0.875\n",
      "Time spent :68.90s\n",
      "k = 12 training accuracy : 0.979\n",
      "k = 12 test accuracy : 0.871\n",
      "Time spent :123.38s\n",
      "k = 12 training accuracy : 0.980\n",
      "k = 12 test accuracy : 0.880\n",
      "Time spent :237.10s\n",
      "Total Time spent : 489.98s\n"
     ]
    }
   ],
   "source": [
    "n_luts_list =[[64]*2**i+[1] for i in range(6)]  # number of luts per layer\n",
    "n_layers = [2**i+1 for i in range(6)]\n",
    "k = 12 # sampling input\n",
    "\n",
    "nn_list = []\n",
    "\n",
    "indexes_0 = np.where(y_train == 0) \n",
    "indexes_1 = np.where(y_train == 1)\n",
    "\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for n in range(len(n_luts_list)):\n",
    "    interm = time.time()\n",
    "    n_luts = n_luts_list[n]\n",
    "    nn = NLUTS(k,n_luts, n_layers[n])\n",
    "    outputs = nn.train(X_train,y_train, indexes_0, indexes_1)\n",
    "    nn_list.append(nn)\n",
    "    print(\"k = {} training accuracy : {:.3f}\".format(k,accuracy_score(y_train, outputs)))\n",
    "    train_accuracy.append(accuracy_score(y_train, outputs))\n",
    "    print(\"k = {} test accuracy : {:.3f}\".format(k,nn.score(X_test,y_test)))\n",
    "    test_accuracy.append(nn.score(X_test,y_test))\n",
    "    \n",
    "    end = time.time() - interm\n",
    "    print(\"Time spent :{:.2f}s\".format(end))\n",
    "end = time.time() - start\n",
    "print(\"Total Time spent : {:.2f}s\".format(end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 12 training accuracy : 0.840\n",
      "k = 12 test accuracy : 0.817\n",
      "Time spent :18.46s\n",
      "k = 12 training accuracy : 0.940\n",
      "k = 12 test accuracy : 0.893\n",
      "Time spent :31.76s\n",
      "k = 12 training accuracy : 0.980\n",
      "k = 12 test accuracy : 0.898\n",
      "Time spent :62.44s\n",
      "k = 12 training accuracy : 0.989\n",
      "k = 12 test accuracy : 0.892\n",
      "Time spent :121.85s\n",
      "k = 12 training accuracy : 0.989\n",
      "k = 12 test accuracy : 0.883\n",
      "Time spent :244.77s\n",
      "k = 12 training accuracy : 0.990\n",
      "k = 12 test accuracy : 0.887\n",
      "Time spent :506.47s\n",
      "Total Time spent : 985.77s\n"
     ]
    }
   ],
   "source": [
    "n_luts_list =[[128]*2**i+[1] for i in range(6)]  # number of luts per layer\n",
    "n_layers = [2**i+1 for i in range(6)]\n",
    "k = 12 # sampling input\n",
    "\n",
    "nn_list = []\n",
    "\n",
    "indexes_0 = np.where(y_train == 0) \n",
    "indexes_1 = np.where(y_train == 1)\n",
    "\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for n in range(len(n_luts_list)):\n",
    "    interm = time.time()\n",
    "    n_luts = n_luts_list[n]\n",
    "    nn = NLUTS(k,n_luts, n_layers[n])\n",
    "    outputs = nn.train(X_train,y_train, indexes_0, indexes_1)\n",
    "    nn_list.append(nn)\n",
    "    print(\"k = {} training accuracy : {:.3f}\".format(k,accuracy_score(y_train, outputs)))\n",
    "    train_accuracy.append(accuracy_score(y_train, outputs))\n",
    "    print(\"k = {} test accuracy : {:.3f}\".format(k,nn.score(X_test,y_test)))\n",
    "    test_accuracy.append(nn.score(X_test,y_test))\n",
    "    \n",
    "    end = time.time() - interm\n",
    "    print(\"Time spent :{:.2f}s\".format(end))\n",
    "end = time.time() - start\n",
    "print(\"Total Time spent : {:.2f}s\".format(end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
